{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/collaborators/","title":"Collaborators","text":"<p>Comming Soon...</p>"},{"location":"about/faqs/","title":"FAQs","text":""},{"location":"about/faqs/#why-cant-you-register-a-quartet-data-portal-account-by-yourself","title":"Why can't you register a Quartet Data Portal account by yourself?","text":"<p>The reason there is no \"Register\" button is that the general process is for users to apply for reference materials as a guest first. This is to facilitate the confirmation of the applicant's information as well as to build a trust and consensus between the two parties, and at all times applicants should avoid uploading and analyzing non-Quartet data on our platform.</p>"},{"location":"about/members/","title":"Members","text":"<p>Comming Soon...</p>"},{"location":"about/news/","title":"News","text":""},{"location":"about/news/#june-3-2023","title":"June 3, 2023","text":"<ul> <li>Documentation Improvement<ul> <li>Add more details about the policies (data request, data submission, account registration, reference materials).</li> </ul> </li> </ul>"},{"location":"about/news/#mar-4-2023","title":"Mar 4, 2023","text":"<ul> <li> <p>Documentation Improvement</p> <ul> <li>Add a document for the local version of DNA-seq qc report.</li> </ul> </li> <li> <p>Release docker images</p> <ul> <li>quartet-dnaqc-report</li> </ul> </li> </ul>"},{"location":"about/news/#feb-17-2023","title":"Feb 17, 2023","text":"<ul> <li> <p>Documentation Improvement</p> <ul> <li>Add a document for the local version of Proteomics qc report.</li> <li>Add a document for the local version of Metabolomics qc report.</li> <li>Add a document for the local version of RNA-seq qc report.</li> </ul> </li> <li> <p>Release docker images</p> <ul> <li>quartet-rseqc-report</li> <li>quartet-protqc-report</li> <li>quartet-metqc-report</li> </ul> </li> </ul>"},{"location":"about/news/#oct-8-2022","title":"Oct 8, 2022","text":"<ul> <li>Documentation Improvement<ul> <li>Add publications</li> <li>Add a document for proteomics qc report.</li> <li>Add a document for metabolomics qc report.</li> </ul> </li> </ul>"},{"location":"about/news/#sep-7-2022","title":"Sep 7, 2022","text":"<ul> <li> <p>DocSys Improvement</p> <ul> <li>Add a third-party comment system to the footer</li> <li>Add a language switcher in the header of doc (English and Chinese.)</li> </ul> </li> <li> <p>Documentation Improvement</p> <ul> <li>Add a Chinese document for ossutil</li> </ul> </li> </ul>"},{"location":"about/news/#sep-6-2022","title":"Sep 6, 2022","text":"<ul> <li> <p>Backend Improvement</p> <ul> <li>Add a new api for checking projects' status.</li> <li>Improve the DNA app to remove the limitations on file name.</li> <li>Improve the statistics of job process.</li> </ul> </li> <li> <p>UI Improvement</p> <ul> <li>Track your jobs with project status </li> </ul> </li> <li> <p>Documentation Improvement</p> <ul> <li>Update the document for data tranfer tools (The ossutil the preferred option.)</li> </ul> </li> </ul>"},{"location":"about/news/#april-15-2022","title":"April 15, 2022","text":"<ul> <li> <p>Added new branch <code>quartet-data-portal-dev</code> for faster release.</p> <p>Release new features at any time, but its stability is not guaranteed. If you need a stable release, please access <code>quartet-data-portal</code>.</p> <p><code>quartet-data-portal-dev</code>: http://dev.chinese-quartet.org</p> <p><code>quartet-data-portal</code>: https://chinese-quartet.org</p> </li> <li> <p>Improved the performance: opening time of the first screen is from 5-6 seconds to 1-2 seconds.</p> </li> </ul>"},{"location":"about/publications/","title":"Publications","text":""},{"location":"about/publications/#main-paper","title":"Main Paper","text":"<ul> <li>Zheng, Y. et al. Ratio-based multiomic profiling using universal reference materials empowers data integration [Unpublished manuscript]. (2022).</li> </ul>"},{"location":"about/publications/#genomics","title":"Genomics","text":"<ul> <li>Ren, L. et al. Quartet DNA reference materials and datasets for comprehensively evaluating germline variants calling performance [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.28.509844</li> <li>Jia, P. et al. Haplotype-resolved assemblies and variant benchmark of a Chinese Quartet [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.08.504083</li> </ul>"},{"location":"about/publications/#transcriptomics","title":"Transcriptomics","text":"<ul> <li>Yu, Y. et al. Quartet RNA reference materials and ratio-based reference datasets for reliable transcriptomic profiling [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507265</li> </ul>"},{"location":"about/publications/#proteomics","title":"Proteomics","text":"<ul> <li>Tian, S. et al. Quartet protein reference materials and datasets for multi-platform assessment of label-free proteomics [Unpublished manuscript] (2022)</li> </ul>"},{"location":"about/publications/#metabolomics","title":"Metabolomics","text":"<ul> <li>Quartet metabolite reference materials and datasets for inter-laboratory reliability assessment of metabolomics studies [Unpublished manuscript] (2022)</li> </ul>"},{"location":"about/publications/#batch-effect","title":"Batch Effect","text":"<ul> <li>Yu, Y. et al. Correcting batch effects in large-scale multiomic studies using a reference-material-based ratio method [Unpublished manuscript] (2022)</li> </ul>"},{"location":"about/publications/#database-webserver","title":"Database &amp; Webserver","text":"<ul> <li>Yang, J. et al. The Quartet Data Portal: integration of community-wide resources for multiomics quality control [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507202</li> </ul>"},{"location":"data_dictionary/metadata/","title":"Metadata","text":""},{"location":"data_dictionary/metadata/#notes","title":"NOTES","text":"<ul> <li>These fields are applicable to all omics technologies.</li> <li>If there is something you do not understand, please download the historical metadata at the Quartet Data Portal to learn more about its meaning.</li> <li>The \"from\" column indicates the source of the field.</li> </ul>"},{"location":"data_dictionary/metadata/#metadata-schema","title":"Metadata Schema","text":"key name short description type collection from project_id Project Id Project Id Identity of the project. category quartet project project_name Project Name Project Name Name of the project. category quartet project project_type Project Type Project Type Type of the project. category quartet project project_description Project Description Project Description Description of the project. category quartet project investigator_name Investigator Name Pi Name Name of the investigator. category quartet project investigator_affiliation Investigator Affiliation Pi Aff Affiliation of the investigator. category quartet project support_id Support Id Support Id ID of the project funded. category quartet project support_source Support Source Support Source Source of the project funded. category quartet project date_collected Date Collected Date Collect Collection date. number quartet project availability_type Availability Type Avail Type Data privacy. category quartet project donor_id Donor Id Donor Id Identity of the donor. category quartet donor family_id Family Id Family Id Identity of the family. category quartet donor pedigree Pedigree Pedigree Pedigree of the family category quartet donor gender Gender Gender Gender of the donor. category quartet donor birth_date Birth Date Birthday Birthday of the donor. number quartet donor biospecimen_id Biospecimen Id Biospecimen Id Identity of the biospecimen. category quartet biospecimen biospecimen_name Biospecimen Name Biospecimen Name Name of the biospecimen. category quartet biospecimen biospecimen_type Biospecimen Type Biospecimen Type Type of the biospecimen. category quartet biospecimen collection_date Collection Date Collect Date Sample collection date. number quartet biospecimen rm_id Rm Id Rm Id Identity of the RM. category quartet reference_materials extraction_site Extraction Site Extract Site Site of the extraction. category quartet reference_materials lot_no Lot No Lot No Number of batch. number quartet reference_materials cell_line_passage_number Cell Line Passage Number Clp Number Number of cell line passage. number quartet reference_materials rm_type Rm Type Rm Type Type of the RM. category quartet reference_materials source Source Source Source of the sample.(eg. Blood, cell, etc.) category quartet reference_materials cell_collection_date Cell Collection Date Cell Collect Date Data of cell collcollectionction. number quartet reference_materials extraction_date Extraction Date Extract Date Data of materials extraction. number quartet reference_materials kit_cat_no Kit Cat No Kit Cat No Number kit cat. number quartet reference_materials kit_lot_no Lot Lot No Kit Cat Number kit lot. number quartet reference_materials extraction_protocol Extraction Extract Protocol of extraction. number quartet reference_materials library_id Library Id Library Id Identity of the library. number quartet library input_ng Input Ng Input Ng Concentration of input. precision quartet library enrich_kit Enrich Kit Enrich Kit Kit of library enrichment. category quartet library preparation_kit Preparation Kit Prep Kit Kit of preperation. category quartet library fragment_method Fragment Method Fragment Method Method of the fragment. category quartet library fragment_selection Fragment Selection Fragment Select Selection of the fragment. category quartet library fragment_range Fragment Range Fragment Range Range of the fragment. precision quartet library pcr_cycle Pcr Cycle Pcr Cycle Cycle of PCR number quartet library preparation_date Preparation Date Prep Date Date of preperation. number quartet library spike_in Spike In Spike In Spike_in added in the library construction.PreparationpreparationPreparationpreparation category quartet library qc_concentration Qc Concentration Qc Conc Concentration of quality control. precision quartet library qc_size Qc Size Qc Size Size of quality control. precision quartet library preparation_method Preperation Method Prep Method Method of preparation. category quartet library preparation_site Preparation Site Prep Site Site of preparation category quartet library batch Library Batch Lib Batch Batch of library category quartet library stranded Library Type Lib Type Type of library category quartet library sequencing_id Sequencing Id Seq Id ID of sequencing. number quartet sequencing site Site Site Site of sequencing. category quartet sequencing platform Platform Platform Platform of sequencing. category quartet sequencing method Method Method Method of sequencing. category quartet sequencing index_sequence Index Sequence Index Seq Index of sequencing. category quartet sequencing flowcell_id Flowcell Id Flowcell Id Identity of the flowcell. category quartet sequencing lane_no Lane No Lane No Number of the lane. number quartet sequencing run_date Run Date Run Date Date of process running. number quartet sequencing datafile_id Datafile Id Datafile Id Identity of the data file. category quartet datafile submitter_id Submitter Id Submitter Id Identity of the submitter. category quartet datafile data_type Data Type Data Type Type of the data file. category quartet datafile data_category Data Category Data Cat Category of the data file. category quartet datafile data_format Data Format Data Format Format of the data file. category quartet datafile file_name File Name File Name Name of the data file. category quartet datafile file_size File Size File Size Size of the datafile. precision quartet datafile md_5sum Md5Sum Md5 The 128-bit hash value expressed as a 32 digit hexadecimal number (in lower case) used as a file's digital fingerprint. category quartet datafile file_path File Path File Path Path of the date file. category quartet datafile node Node Id Node Id Identity of the Node URL. category quartet datafile analyses_id Analyses Id Analyze Id Identity of the analyses. category quartet analyses analyses_type Analyses Type Analyze Type Type of the analyses. category quartet analyses link Link Link Link of the analyses. category quartet analyses version Version Version Version of the analyses. category quartet analyses"},{"location":"data_pipelines/intro/","title":"Introduction","text":""},{"location":"data_pipelines/intro/#genomics","title":"Genomics","text":"<p>For whole-genome sequencing, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment quality assessment, post-alignment assessment, and small variants calling results assessment. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap. The performance of variants calling results are evaluated by reference datasets and Quartet family-dependent built-in genetic truth. MultiQC was used for compiling QC results together. Pre-alignment and Post-alignment quality assessment are not available if user start from VCF files.</p>"},{"location":"data_pipelines/intro/#transcriptomics","title":"Transcriptomics","text":"<p>For RNA-seq, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment, post-alignment, and gene-expression profiles. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap, while the quality control of gene expression profiles is based on the Quartet reference datasets and the internal information of each batch itself. MultiQC was used for compiling QC results together.</p>"},{"location":"data_pipelines/intro/#proteomics","title":"Proteomics","text":"<p>For proteomics, the quality assessment is started from expression profiles formatted as .csv files, and the pipeline is implemented into QC Report module. It is based on built-in biological differences of the samples and consistency with the reference dataset at relative quantitation levels. The former is scored as an Signal-to-Noise Ratio (SNR) and displayed in a PCA scatterplot, and the latter is scored as Pearson correlation to the reference dataset and displayed in a scatterplot, in which a strict filter criteria was applied (features with p.adj&lt;0.05 in at least 4 batches were kept). MultiQC was used for compiling QC results together.</p>"},{"location":"data_pipelines/intro/#metabolomics","title":"Metabolomics","text":"<p>Quality Assessment of a Quartet metabolic profiling dataset is based on built-in biological differences of the samples, consistency with the reference dataset at relative quantitation levels. The three QC metrics, including Signal-to-Noise Ratio (SNR), Relative Correlation with Reference Datasets (RC), and Recall of DAMs in Reference Datasets (Recall), to comprehensively assess the performance of metabolic profiles from 2 aspects: reproducibility and accuracy.</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wes/","title":"Analysis Pipeline for WES","text":"<p>More details is comming soon. Before that, you can follow the WGS documentation.</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/","title":"Analysis Pipeline for WGS","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#quality-control-pipeline-for-wgs","title":"Quality control pipeline for WGS","text":"<p>This Quartet quality control pipeline evaluate the performance of reads quality and variant calling quality. This pipeline accepts FASTQ format input files or VCF format input files. If the users input FASTQ files, this APP will output the results of pre-alignment quality control from FASTQ files, post-alignment quality control from BAM files and variant calling quality control from VCF files. GATK best practice pipelines (implemented by SENTIEON software) were used to map reads to the reference genome and call variants. If the users input VCF files, this APP will only output the results of variant calling quality control.</p> <p>Quartet quality control analysis pipeline started from FASTQ files is implemented across seven main procedures:</p> <ul> <li>Pre-alignment QC of FASTQ files</li> <li>Genome alignment</li> <li>Post-alignment QC of BAM files</li> <li>Germline variant calling</li> <li>Variant calling QC depended on benchmark sets of VCF files</li> <li>Check Mendelian inheritance states across four Quartet samples of every variants</li> <li>Variant calling QC depended on Quartet genetic relationship of VCF files</li> </ul> <p>Quartet quality control analysis pipeline started from VCF files is implemented across three main procedures:</p> <ul> <li>Variant calling QC depended on benchmark sets of VCF files</li> <li>Check Mendelian inheritance states across four Quartet samples of every variants</li> <li>Variant calling QC depended on Quartet genetic relationship of VCF files</li> </ul> <p></p> <p>Results generated from this APP can be visualized by QDP report.</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#1-pre-alignment-qc-of-fastq-files","title":"1. Pre-alignment QC of FASTQ files","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#fastqc-v0115","title":"Fastqc v0.11.5","text":"<p>FastQC is used to investigate the quality of fastq files</p> <pre><code>fastqc -t &lt;threads&gt; -o &lt;output_directory&gt; &lt;fastq_file&gt;\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#fastq-screen-0120","title":"Fastq Screen 0.12.0","text":"<p>Fastq Screen is used to inspect whether the library were contaminated. For example, we expected 99% reads aligned to human genome, 10% reads aligned to mouse genome, which is partly homologous to human genome. If too many reads are aligned to E.Coli or Yeast, libraries or cell lines are probably comtminated.</p> <pre><code>fastq_screen --aligner &lt;aligner&gt; --conf &lt;config_file&gt; --top &lt;number_of_reads&gt; --threads &lt;threads&gt; &lt;fastq_file&gt;\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#2-genome-alignment","title":"2. Genome alignment","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#sentieon-genomicsv20191128","title":"sentieon-genomics:v2019.11.28","text":"<p>Reads were mapped to the human reference genome GRCh38 using Sentieon BWA.</p> <pre><code>${SENTIEON_INSTALL_DIR}/bin/bwa mem -M -R \"@RG\\tID:${group}\\tSM:${sample}\\tPL:${pl}\" -t $nt -K 10000000 ${ref_dir}/${fasta} ${fastq_1} ${fastq_2} | ${SENTIEON_INSTALL_DIR}/bin/sentieon util sort -o ${sample}.sorted.bam -t $nt --sam2bam -i -\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#3-post-alignment-qc","title":"3. Post-alignment QC","text":"<p>Qualimap and Paicard Tools (implemented by Sentieon) are used to check the quality of BAM files. Deduplicated BAM files are used in this step.</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#qualimap-200","title":"Qualimap 2.0.0","text":"<pre><code>qualimap bamqc -bam &lt;bam_file&gt; -outformat PDF:HTML -nt &lt;threads&gt; -outdir &lt;output_directory&gt; --java-mem-size=32G </code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#sentieon-genomicsv20191128_1","title":"Sentieon-genomics:v2019.11.28","text":"<pre><code>${SENTIEON_INSTALL_DIR}/bin/sentieon driver -r ${ref_dir}/${fasta} -t $nt -i ${Dedup_bam} --algo CoverageMetrics --omit_base_output ${sample}_deduped_coverage_metrics --algo MeanQualityByCycle ${sample}_deduped_mq_metrics.txt --algo QualDistribution ${sample}_deduped_qd_metrics.txt --algo GCBias --summary ${sample}_deduped_gc_summary.txt ${sample}_deduped_gc_metrics.txt --algo AlignmentStat ${sample}_deduped_aln_metrics.txt --algo InsertSizeMetricAlgo ${sample}_deduped_is_metrics.txt --algo QualityYield ${sample}_deduped_QualityYield.txt --algo WgsMetricsAlgo ${sample}_deduped_WgsMetricsAlgo.txt\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#4-germline-variant-calling","title":"4. Germline variant calling","text":"<p>HaplotyperCaller implemented by Sentieon is used to identify germline variants.</p> <pre><code>${SENTIEON_INSTALL_DIR}/bin/sentieon driver -r ${ref_dir}/${fasta} -t $nt -i ${recaled_bam} --algo Haplotyper ${sample}_hc.vcf\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#5-variants-calling-qc","title":"5. Variants Calling QC","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#51-performance-assessment-based-on-benchmark-sets","title":"5.1 Performance assessment based on benchmark sets","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#happy-v039","title":"Hap.py v0.3.9","text":"<p>Variants were compared with benchmark calls in benchmark regions.</p> <pre><code>hap.py &lt;truth_vcf&gt; &lt;query_vcf&gt; -f &lt;bed_file&gt; --threads &lt;threads&gt; -o &lt;output_filename&gt;\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#52-performance-assessment-based-on-quartet-genetic-built-in-truth","title":"5.2 Performance assessment based on Quartet genetic built-in truth","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#vbt-v11","title":"VBT v1.1","text":"<p>We splited the Quartet family to two trios (F7, M8, D5 and F7, M8, D6) and then do the Mendelian analysis. A Quartet Mendelian concordant variant is the same between the twins (D5 and D6) , and follow the Mendelian concordant between parents (F7 and M8). Mendelian concordance rate is the Mendelian concordance variant divided by total detected variants in a Quartet family. Only variants on chr1-22,X are included in this analysis.</p> <pre><code>vbt mendelian -ref &lt;fasta_file&gt; -mother &lt;family_merged_vcf&gt; -father &lt;family_merged_vcf&gt; -child &lt;family_merged_vcf&gt; -pedigree &lt;ped_file&gt; -outDir &lt;output_directory&gt; -out-prefix &lt;output_directory_prefix&gt; --output-violation-regions -thread-count &lt;threads&gt;\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#input-files","title":"Input files","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#1-start-from-fastq-files","title":"1. Start from Fastq files","text":"<pre><code>sample_id,project,fastq_1_D5,fastq_2_D5,fastq_1_D6,fastq_2_D6,fastq_1_F7,fastq_2_F7,fastq_1_M8,fastq_2_M8\n# sample_id in choppy system\n# project name\n# oss path of D5 fastq read1 file\n# oss path of D5 fastq read2 file\n# oss path of D6 fastq read1 file\n# oss path of D6 fastq read2 file\n# oss path of F7 fastq read1 file\n# oss path of F7 fastq read2 file\n# oss path of M8 fastq read1 file\n# oss path of M8 fastq read2 file\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#2-start-from-vcf-files","title":"2. Start from VCF files","text":"<pre><code>sample_id,project,vcf_D5,vcf_D6,vcf_F7,vcf_M8\n# sample_id in choppy system\n# project name\n# oss path of D5 VCF file\n# oss path of D6 VCF file\n# oss path of F7 VCF file\n# oss path of M8 VCF file\n</code></pre>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#output-files","title":"Output Files","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#1-extract_tableswdlextract_tables_vcfwdl","title":"1. extract_tables.wdl/extract_tables_vcf.wdl","text":"<p>(FASTQ) Pre-alignment QC: pre_alignment.txt</p> <p>(FASTQ) Post-alignment QC: post_alignment.txt</p> <p>(FASTQ/VCF) Variants calling QC: variants.calling.qc.txt</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#2-quartet_mendelianwdl","title":"2. quartet_mendelian.wdl","text":"<p>(FASTQ/VCF) Variants calling QC: mendelian.txt</p>"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#output-files-format","title":"Output files format","text":""},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#1-pre_alignmenttxt","title":"1. pre_alignment.txt","text":"Column name Description Sample Sample name %Dup Percentage duplicate reads %GC Average GC percentage Total Sequences (million) Total sequences %Human Percentage of reads mapped to human genome %EColi Percentage of reads mapped to Ecoli %Adapter Percentage of reads mapped to adapter %Vector Percentage of reads mapped to vector %rRNA Percentage of reads mapped to rRNA %Virus Percentage of reads mapped to virus %Yeast Percentage of reads mapped to yeast %Mitoch Percentage of reads mapped to mitochondrion %No hits Percentage of reads not mapped to genomes mentioned above"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#2-post_alignmenttxt","title":"2.  post_alignment.txt","text":"Column name Description Sample Sample name %Mapping Percentage of mapped reads %Mismatch Rate Mapping error rate Mendelian Insert Size Median insert size\uff08bp\uff09 %Q20 Percentage of bases &gt;Q20 %Q30 Percentage of bases &gt;Q30 Mean Coverage Mean deduped coverage Median Coverage Median deduped coverage PCT_1X Fraction of genome with at least 1x coverage PCT_5X Fraction of genome with at least 5x coverage PCT_10X Fraction of genome with at least 10x coverage PCT_30X Fraction of genome with at least 30x coverage"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#3-variantscallingqctxt","title":"3. variants.calling.qc.txt","text":"Column name Description Sample Sample name SNV number Total SNV number (chr1-22,X) INDEL number Total INDEL number (chr1-22,X) SNV query SNV number in benchmark region INDEL query INDEL number in benchmark region SNV TP True positive SNV INDEL TP True positive INDEL SNV FP False positive SNV INDEL FP True positive INDEL SNV FN False negative SNV INDEL FN False negative INDEL SNV precision Precision of SNV calls when compared with benchmark calls in benchmark regions INDEL precision Precision of INDEL calls when compared with benchmark calls in benchmark regions SNV recall Recall of SNV calls when compared with benchmark calls in benchmark regions INDEL recall Recall of INDEL calls when compared with benchmark calls in benchmark regions SNV F1 F1 score of SNV calls when compared with benchmark calls in benchmark regions INDEL F1 F1 score of INDEL calls when compared with benchmark calls in benchmark regions"},{"location":"data_pipelines/genomics/analysis_pipeline_wgs/#4-projectsummarytxt","title":"4 {project}.summary.txt","text":"Column name Description Family Family name defined by inputed project name Reproducibility_D5_D6 Percentage of variants were shared by the twins (D5 and D6) Mendelian_Concordance_Quartet Percentage of variants were Mendelian concordance"},{"location":"data_pipelines/genomics/intro/","title":"Introduction","text":""},{"location":"data_pipelines/genomics/intro/#chinese-quartet-dna-reference-materials","title":"Chinese Quartet DNA reference materials","text":"<p>With the rapid development of sequencing technology and the dramatic decrease of sequencing costs, DNA sequencing has been widely used in scientific research, diagnosis of and treatment selection for human diseases. However, due to the lack of effective quality assessment and control of the high-throughput omics data generation and analysis processes, variants calling results are seriously inconsistent among different technical replicates, batches, laboratories, sequencing platforms, and analysis pipelines, resulting in irreproducible scientific results and conclusions, huge waste of resources, and even endangering the life and health of patients. Therefore, reference materials for quality control of the whole process from omics data generation to data analysis are urgently needed. </p> <p>We first established genomic DNA reference materials from four immortalized B-lymphoblastoid cell lines of a Chinese Quartet family including parents and monozygotic twin daughters to make performance assessment of germline variants calling results. To establish small variant benchmark calls and regions, we generated whole-genome sequencing data in nine batches, with depth ranging from 30x to 60x, by employing PCR-free and PCR libraries on four popular short-read sequencing platforms (Illumina HiSeq XTen, Illumina NovaSeq, MGISEQ-2000, and DNBSEQ-T7) with three replicates at each batch, resulting in 108 libraries in total and 27 libraries for each Quartet DNA reference material. Then, we selected variants concordant in multiple call sets and in Mendelian consistency within Quartet family members as small variant benchmark calls, resulting in 4.2 million high-confidence variants (SNV and Indel) and 2.66 G high confidence genomic region, covering 87.8% of the human reference genome (GRCh38, chr1-22 and X). Two orthogonal technologies were used for verifying the high-confidence variants. The consistency rate with PMRA (Axiom Precision Medicine Research Array) was 99.6%, and 95.9% of high-confidence variants were validated by 10X Genomics whole-genome sequencing data. Genetic built-in truth of the Quartet family design is another kind of \u201ctruth\u201d within the four Quartet samples. Apart from comparison with benchmark calls in the benchmark regions to identify false-positive and false-negative variants, pedigree information among the Quartet DNA reference materials, i.e., reproducibility rate of variants between the twins and Mendelian concordance rate among family members, are complementary approaches to comprehensively estimate genome-wide variants calling performance. Finally, we developed a whole-genome sequencing data quality assessment pipeline and demonstrated its utilities with two examples of using the Quartet reference materials and datasets to evaluate data generation performance in three sequencing labs and different data analysis pipelines.</p>"},{"location":"data_pipelines/genomics/intro/#requirements-for-your-data-and-metadata","title":"Requirements for your data and metadata","text":"<ul> <li><code>Metadata Template</code> - Download the metadata template and prepare your metabata</li> <li><code>Data Format</code> - Follow the data format requirements to prepare your genomics data</li> </ul>"},{"location":"data_pipelines/genomics/intro/#analyze-your-data-on-quartet-data-portal","title":"Analyze your data on Quartet Data Portal","text":"<p>See more details on Step by Step Guide</p>"},{"location":"data_pipelines/genomics/intro/#analyze-your-data-on-your-own-server","title":"Analyze your data on your own server","text":"<p>Quartet DSeQC Report is a quality assessment tool for WGS/WES data. It supports two format: <code>Fastq</code> and <code>vcf</code>. And it contains three subcommands: <code>fq-workflow</code>, <code>vcf-workflow</code> and <code>report</code>. The <code>fq-workflow</code> command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on DNA-Seq (WGS) QC for Quartet and DNA-Seq (WES) QC for Quartet).</p> <p>When you have produced vcf files from your own pipeline, you can use the <code>vcf-workflow</code> command. It takes vcf files and produces a set of qc result files from them. </p> <p>After above processes, you can use <code>report</code> command to report the results finally (More details on QC Report for Quartet RNA-Seq).</p>"},{"location":"data_pipelines/genomics/intro/#if-you-have-raw-reads-in-fastq-format","title":"If you have raw reads (in FASTQ format)","text":"<p>CAUTION</p> <p>The pipeline for raw reads depends on Sentieon software. So if you want to use the pipeline, you need to specify the license server by <code>-S</code> option. </p> <p>If you don't have the license, we recommend you analyze your data on Quartet Data Portal. If not, please contact Sentieon or use the vcf mode.</p> <p>If you have your own pipeline, you can use your own pipeline to produce vcf files from your raw reads. Then you can use the <code>vcf-workflow</code> command to analyze your data. More details at the following section.</p> <p>[STATEMENT: We don't have any relationship with Sentieon and don't get any benefit from Sentieon.]</p> <p>Assuming your data files are in the /your-dir directory.</p> <ol> <li> <p>Prepare a set of subdirectories</p> <pre><code>mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report\n</code></pre> </li> <li> <p>Download the dependency files</p> <pre><code>wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1\n\nunzip quartet-dseqc-report-reference-data-v20230404.zip\n\n# You need to place the reference files into /your-dir/references directory\n</code></pre> </li> <li> <p>Place your data files into <code>/your-dir/raw-data</code> directory</p> </li> <li> <p>Pull docker image </p> <p>More versions on Docker Registry</p> <pre><code>docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a\n</code></pre> </li> <li> <p>Generate qc result files by workflow command</p> <pre><code># For WGS Fastq data\n## Assume the following conditions:\n### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz\n### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.]\n### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA\n### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server.\n### 5. The output directory is /your-dir/results\n\ndocker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --output-dir /data/results\n\n# For WES Fastq data\n## Assume the following conditions:\n### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz\n### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.]\n### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA\n### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server.\n### 5. You need to prepare your bed file and set -b option.\n### 6. The output directory is /your-dir/results\n\ndocker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --bed-file /data/references/your-bed-file --output-dir /data/results\n</code></pre> </li> <li> <p>Report the results</p> <pre><code>docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report\n</code></pre> </li> <li> <p>Find your QC report in <code>/your-dir/report/multiqc_report.html</code></p> </li> </ol>"},{"location":"data_pipelines/genomics/intro/#if-you-have-vcf-files","title":"If you have vcf files","text":"<p>Assuming your data files are in the /your-dir directory.</p> <ol> <li> <p>Prepare a set of subdirectories</p> <pre><code>mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report\n</code></pre> </li> <li> <p>Download the dependency files</p> <pre><code>wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1\n\nunzip quartet-dseqc-report-reference-data-v20230404.zip\n\n# You need to place the reference files into /your-dir/references directory\n</code></pre> </li> <li> <p>Place your data files into <code>/your-dir/raw-data</code> directory</p> </li> <li> <p>Pull docker image </p> <p>More versions on Docker Registry</p> <pre><code>docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a\n</code></pre> </li> <li> <p>Generate qc result files by workflow command</p> <pre><code># For WGS data\n## Assume the following conditions:\n### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.]\n### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA\n### 3. The output directory is /your-dir/results\n\ndocker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --output-dir /data/results\n\n# For WES data\n## Assume the following conditions:\n### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.]\n### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA\n### 3. You need to prepare your bed file and set -b option.\n### 4. The output directory is /your-dir/results\n\ndocker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --bed-file /data/references/your-bed-file --output-dir /data/results\n</code></pre> </li> <li> <p>Report the results</p> <pre><code>docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report\n\n# Known issue:\n# Only support one uuid directory in /your-dir/results directory.\n# If you have multiple uuid directories in /your-dir/results directory, the report will be failed or messy.\n# We will fix this issue in the future.\n</code></pre> </li> <li> <p>Find your QC report in <code>/your-dir/report/multiqc_report.html</code></p> </li> </ol>"},{"location":"data_pipelines/genomics/intro/#more-details-about-the-analysis-pipeline","title":"More details about the analysis pipeline","text":"<ul> <li><code>QC APP</code> - WGS QC for Quartet</li> <li><code>QC APP</code> - WES QC for Quartet</li> </ul>"},{"location":"data_pipelines/genomics/metadata_template/","title":"Metadata Template","text":"<p>English or Chinese?</p> <p>English means <code>With English Annotations</code>; </p> <p>Chinese means <code>With Chinese Annotations</code>;</p>"},{"location":"data_pipelines/genomics/metadata_template/#latest-version","title":"Latest Version","text":"<ul> <li><code>English Version - Recommended</code> </li> <li><code>Chinese Version</code></li> </ul>"},{"location":"data_pipelines/genomics/metadata_template/#previous-versions","title":"Previous Versions","text":""},{"location":"data_pipelines/genomics/metadata_template/#20221128-english","title":"20221128 - English","text":"<pre><code>CHANGELOG: \nThis is the first commit.\n</code></pre>"},{"location":"data_pipelines/genomics/metadata_template/#20221128-chinese","title":"20221128 - Chinese","text":"<pre><code>CHANGELOG: \nThis is the first commit.\n</code></pre>"},{"location":"data_pipelines/genomics/omics_data_format/","title":"Omics Data Format","text":""},{"location":"data_pipelines/genomics/omics_data_format/#omics-data-format","title":"Omics Data Format","text":"<p>The data format that can be analyzed online are:</p> <ul> <li> <p>Pair-end FASTQ files, with suffixes of _R1.fastq.gz and _R2.fastq.gz or _R1.fq.gz and _R2.fq.gz.</p> </li> <li> <p>unzipped VCF files, with suffixes of <code>.vcf</code>.</p> </li> </ul> <p>Note</p> <p>In addition, there is one thing to note when using the Quartet DNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of data sets (one technical replicate of each sample is considered as one set, i.e. D5-D6-F7-M8).</p> <p>For example, if you provide data for 8 samples, that means two sets of data, so fill in \"2\".</p>"},{"location":"data_pipelines/genomics/qc_report/","title":"Qc report","text":"<p>Comming Soon...</p>"},{"location":"data_pipelines/metabolomics/intro/","title":"Introduction","text":""},{"location":"data_pipelines/metabolomics/intro/#requirements-for-your-data-and-metadata","title":"Requirements for your data and metadata","text":"<ul> <li><code>Metadata Template</code> - Download the metadata template and prepare your metabata</li> <li><code>Data Format</code> - Follow the data format requirements to prepare your genomics data</li> </ul>"},{"location":"data_pipelines/metabolomics/intro/#guide-for-qc-reports","title":"Guide for QC Reports","text":"<ul> <li><code>QC Report</code> - QC Report for Quartet Metabolomics</li> </ul>"},{"location":"data_pipelines/metabolomics/metadata_template/","title":"Metadata Template","text":"<p>English or Chinese?</p> <p>English means <code>With English Annotations</code>; </p>"},{"location":"data_pipelines/metabolomics/metadata_template/#latest-version","title":"Latest Version","text":"<ul> <li><code>English Version - Recommended</code> </li> </ul>"},{"location":"data_pipelines/metabolomics/qc_report/","title":"QC Report","text":"<p>From Quantified Expression Profiles to QC Report for Metabolomics (targeted and untargeted)</p> <p>.csv format of quantified expression profiles at metabolite level</p> <p>Note</p> <p>You can find the source code on chinese-quartet/quartet-metqc-report</p>"},{"location":"data_pipelines/metabolomics/qc_report/#prepare-data-metadata-files","title":"Prepare data &amp; metadata files","text":""},{"location":"data_pipelines/metabolomics/qc_report/#data-file","title":"Data File","text":"<p>The data file provides quantitative information on Quartet samples at the metabolite level.  1. The data file should be comma separated values (<code>.csv</code>) or tab delimited text (<code>.txt</code>) with a header in the first row.</p> <ol> <li> <p>Samples should be in the columns of the file. </p> </li> <li> <p>Quantitative results should be given in the form of concentrations or peak intensities and contain only numeric and positive values. </p> </li> <li> <p>Two columns accurately named \"metabolites\" and \"HMDBID\" are needed, which contain the name of the metabolite compound and HMDBID, respectively. If HMDBID is not available, use \"NA\" for missing values in the data file.</p> </li> <li> <p>Both sample or metabolite compound names must be unique and consist of a combination of common English letters, underscores and numbers for naming purpose. Sample name should not be started with numbers. Latin/Greek letters are not supported.</p> </li> </ol> <p>More details on https://www.metaboanalyst.ca/docs/Format.xhtml.</p>"},{"location":"data_pipelines/metabolomics/qc_report/#metadata-file","title":"Metadata File","text":"<p>The metadata file has the information of each sample in the data file.  With columns accurately named \"col_names\" (names of samples, identical to their names in the columns of data file), \"strategy\" (Targeted or Untargeted), \"lab\" (the name of lab), \"sample\" (D5, D6, F7 and M8 for Quartet samples), \"rep\" (the replicates for each sample) and \"batch\" (the name of batch).</p> <p>A screenshot of a sample metadata table is shown below.</p> <p></p>"},{"location":"data_pipelines/metabolomics/qc_report/#step-by-step-guide","title":"Step by Step Guide","text":""},{"location":"data_pipelines/metabolomics/qc_report/#analyze-your-data-on-your-own-server","title":"Analyze your data on your own server","text":"<ol> <li> <p>Pull docker image </p> <p>More versions on Docker Registry</p> <pre><code>docker pull ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071\n</code></pre> </li> <li> <p>Run quartet-metqc-report with docker image</p> <p>Assuming that your data file is named <code>data.csv</code> and metadata file is named <code>metadata.csv</code> and all files are placed in <code>/your-dir</code> directory.</p> <pre><code>docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071 -d /data/data.csv -m /data/metadata.csv -o /data\n</code></pre> </li> <li> <p>Find your QC report in <code>/your-dir/multiqc_report.html</code></p> </li> </ol>"},{"location":"data_pipelines/metabolomics/qc_report/#analyze-your-data-on-quartet-data-portal","title":"Analyze your data on Quartet Data Portal","text":"<p>As for running the QC pipeline of metabolomics data, you can:</p> <p>1) go to http://chinese-quartet.org/#/seq-flow/metqc-report-management;</p> <p>2) click the upper right button named \"New QC report\";</p> <p>3) click \"Step 1: Choose Report\", please choose \"QC Report for Quartet Metabolomics\" ;</p> <p>4) click \"Step 2: Upload Files (s)\", please upload your data and metadata files (.csv). </p> <p>5) click \"Step 3: Parameters &amp; Submit\", please fill in the blanks and submit the job.</p> <p>See more details on Step by Step Guide</p>"},{"location":"data_pipelines/proteomics/metadata_template/","title":"Metadata template","text":"<p>Comming Soon...</p>"},{"location":"data_pipelines/proteomics/qc_report/","title":"QC Report","text":"<p>From Quantified Expression Profiles to QC Report</p> <p>Note</p> <p>You can find the source code on chinese-quartet/quartet-protqc-report</p>"},{"location":"data_pipelines/proteomics/qc_report/#prepare-data-metadata-files","title":"Prepare data &amp; metadata files","text":""},{"location":"data_pipelines/proteomics/qc_report/#data-file","title":"Data File","text":"<p>The data file contains gene symbols of each protein and its quantitated expression level in each sample (replicate), and the missing values are allowed. The required file format has samples in columns and a column named \"rowname\". </p> <p>A screenshot of a sample data table is shown below.</p> <p></p>"},{"location":"data_pipelines/proteomics/qc_report/#metadata-file","title":"Metadata File","text":"<p>The metadata file has the information of each sample in the data file. With columns named \"name\", \"sample\" (D5, D6, F7 and M8 for Quartet samples). Remember that the column \"name\" and column names of the data file table must be in one-to-one correspondence. </p> <p>A screenshot of a sample metadata table is shown below.</p> <p></p>"},{"location":"data_pipelines/proteomics/qc_report/#step-by-step-guide","title":"Step by Step Guide","text":""},{"location":"data_pipelines/proteomics/qc_report/#analyze-your-data-on-your-own-server","title":"Analyze your data on your own server","text":"<ol> <li> <p>Pull docker image </p> <p>More versions on Docker Registry</p> <pre><code>docker pull ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.2-27439957\n</code></pre> </li> <li> <p>Run quartet-protqc-report with docker image</p> <p>Assuming that your data file is named <code>data.csv</code> and metadata file is named <code>metadata.csv</code> and all files are placed in <code>/your-dir</code> directory.</p> <pre><code>docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.2-27439957 -d /data/data.csv -m /data/metadata.csv -o /data\n</code></pre> </li> <li> <p>Find your QC report in <code>/your-dir/multiqc_report.html</code></p> </li> </ol>"},{"location":"data_pipelines/proteomics/qc_report/#analyze-your-data-on-quartet-data-portal","title":"Analyze your data on Quartet Data Portal","text":"<p>As for running the QC pipeline of proteomics data, you can:</p> <p>1) go to http://chinese-quartet.org/#/seq-flow/protqc-report-management;</p> <p>2) click the upper right button named \"New QC report\";</p> <p>3) click \"Step 1: Choose Report\", please choose \"QC Report for Quartet Proteomics\" ;</p> <p>4) click \"Step 2: Upload Files (s)\", please upload your data and metadata files (.csv). </p> <p>5) click \"Step 3: Parameters &amp; Submit\", please fill in the blanks and submit the job.</p> <p>See more details on Step by Step Guide</p>"},{"location":"data_pipelines/proteomics/qc_report/#more-details-about-qc-metrics","title":"More details about QC metrics","text":"<p>The package protqc output Quality Control(QC) results of proteomics data for Quartet Project. The QC pipeline starts from the expression profiles at peptide/protein levels, and enables to calculate 6 metrics. A Total score is the geometric mean of the linearly normalized values of these metrics.</p> <ol> <li> <p>Number of features: We expect as many proteins (mapped to gene symbols) as possible for downstreaming analyses.</p> </li> <li> <p>Missing percentage (%): Too many missing values interfere with comparability. This metric is calculated globally.</p> </li> <li> <p>Coefficient of variantion (CV, %): A CV value is calculated to indicate the dispersion within replicates feature by feature.</p> </li> <li> <p>Absolute Correlation: Pearson correlation reflects overall reproducibility within replicates. We calculate correlation coefficients between each two replicates within each biological sample (D5, D6, F7, M8), and take the median as the final value for absolute correlation.</p> </li> <li> <p>Signal-to-Noise Ratio (SNR): SNR is established to characterize the ability of a platform or lab or batch, which is able to distinguish intrinsic differences among distinct biological sample groups (\u201csignal\u201d) from variations in technical replicates of the same sample group (\"noise\").</p> </li> <li> <p>Relative Correlation with Reference Datasets (RC): RC is used for assessment of quantitative consistency with the reference dataset at relative levels. For shotgun proteomics, quantitation at peptide levels is theoretically more reliable. Therefore, the reference dataset is established by benchmarking the relative expression values (log2FCs), for each peptide sequence of each sample pair (D5/D6, F7/D6, M8/D6), in historical datasets at peptide levels. We calculate relatively qualified (satisfied with thresholds of p &lt; 0.05) log2FCs of the queried data, for overlapped peptides with the reference dataset, as the input for the assessment of quantitative consistency. Then RC value is Pearson correlation coefficient between the test dataset and the reference dataset.</p> </li> </ol>"},{"location":"data_pipelines/transcriptomics/analysis_pipeline/","title":"Analysis Pipeline","text":""},{"location":"data_pipelines/transcriptomics/analysis_pipeline/#rnaseq-analysis-pipeline","title":"RNAseq analysis pipeline","text":"<p>Preliminary processing of raw fastq reads was performed using fastp v0.19.6 to remove adapter sequences1. Read alignment and quantification was conducted using HISAT v2.1, SAMtools v1.3.1, StringTie v1.3.4 and Ballgown v2.14.12. Reference human genome build 38 and gene model from Ensembl were used for read mapping and gene quantification. log2 transformation was then conducted based on Fragments Per Kilobase of transcript per Million mapped reads (FPKM) values. To avoid infinite values, a value of 0.01 was added to the FPKM value of each gene before log2 transformation. Expression profiles based on detected genes were used for further analysis. A gene was considered detectable (expressed) in a biological group within a batch if \u2265 3 reads were mapped onto it in at least two of the three replicates.</p> <p>Quality control analysis of sequencing data at pre-alignment and post-alignment level was conducted using FastQC v0.11.53, FastQ Screen v0.12.04, Qualimap v2.0.05, and MultiQC v1.86. </p> <p></p> <p>Results generated from this APP can be visualized by QDP report.</p>"},{"location":"data_pipelines/transcriptomics/analysis_pipeline/#reference","title":"Reference","text":"<ol> <li> <p>Chen, S., Zhou, Y., Chen, Y. &amp; Gu, J. fastp: an ultra-fast all-in-one FASTQ preprocessor. J Bioinformatics 34, i884-i890 (2018).\u00a0\u21a9</p> </li> <li> <p>Pertea, M., Kim, D., Pertea, G.M., Leek, J.T. &amp; Salzberg, S.L. Transcript-level expression analysis of RNA-seq experiments with HISAT, StringTie and Ballgown. Nat Protoc 11, 1650 (2016).\u00a0\u21a9</p> </li> <li> <p>Andrews, S. FastQC: a quality control tool for high throughput sequence data https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.  (2017).\u00a0\u21a9</p> </li> <li> <p>Wingett, S.W. &amp; Andrews, S. FastQ Screen: A tool for multi-genome mapping and quality control. F1000Research 7 (2018).\u00a0\u21a9</p> </li> <li> <p>Garc\u00eda-Alcalde, F. et al. Qualimap: evaluating next-generation sequencing alignment data. Bioinformatics 28, 2678-2679 (2012).\u00a0\u21a9</p> </li> <li> <p>Ewels, P., Magnusson, M., Lundin, S. &amp; K\u00e4ller, M. MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics 32, 3047-3048 (2016).\u00a0\u21a9</p> </li> </ol>"},{"location":"data_pipelines/transcriptomics/intro/","title":"Introduction","text":""},{"location":"data_pipelines/transcriptomics/intro/#requirements-for-your-data-and-metadata","title":"Requirements for your data and metadata","text":"<ul> <li><code>Metadata Template</code> - Download the metadata template and prepare your metabata</li> <li><code>Data Format</code> - Follow the data format requirements to prepare your genomics data</li> </ul>"},{"location":"data_pipelines/transcriptomics/intro/#analyze-your-data-on-quartet-data-portal","title":"Analyze your data on Quartet Data Portal","text":"<p>See more details on Step by Step Guide</p>"},{"location":"data_pipelines/transcriptomics/intro/#analyze-your-data-on-your-own-server","title":"Analyze your data on your own server","text":"<p>Quartet RSeQC Report is a quality assessment tool for RNA-seq data. It contains two subcommands: <code>workflow</code> and <code>report</code>. The workflow command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on RNA-Seq QC for Quartet). and you can use <code>report</code> command to report the results finally (More details on QC Report for Quartet RNA-Seq).</p> <p>Assuming your data files are in the /your-dir directory.</p> <ol> <li> <p>Prepare a set of subdirectories</p> <pre><code>mkdir -p /your-dir/fastq_screen /your-dir/hisat2 /your-dir/gtf /your-dir/results /your-dir/raw-data /your-dir/report\n</code></pre> </li> <li> <p>Download the dependency files</p> <pre><code># 1. Download reference genomes for `fastq_screen` (More details on https://figshare.com/articles/online_resource/fastq_screen_zip/22121078)\nwget https://figshare.com/ndownloader/files/39310673 -O /your-dir/fastq_screen/fastq_screen.zip\nunzip /your-dir/fastq_screen/fastq_screen.zip -d /your-dir/fastq_screen\n\n# 2. Download GTF file (More details on https://figshare.com/articles/online_resource/Homo_sapiens_GRCh38_93_gtf/22117475)\nwget https://figshare.com/ndownloader/files/39308702 -O /your-dir/gtf/Homo_sapiens.GRCh38.93.gtf\n\n# 3. Download Hisat2 index files (More details on https://figshare.com/articles/online_resource/hisat2_zip/22120538)\nwget https://figshare.com/ndownloader/files/39310418 -O /your-dir/hisat2/hisat2.zip\nunzip /your-dir/hisat2/hisat2.zip -d /your-dir/hisat2\n</code></pre> </li> <li> <p>Place your data files into <code>/your-dir/raw-data</code> directory</p> </li> <li> <p>Pull docker image </p> <p>More versions on Docker Registry</p> <pre><code>docker pull ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.3-31f4ef89\n</code></pre> </li> <li> <p>Generate qc result files by workflow command</p> <pre><code>docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.3-31f4ef89 workflow -i /data/hisat2 -g /data/gtf/gencode.v36.annotation.gtf -s /data/fastq_screen/fastq_screen.conf --output-dir /data/results --r1 /data/raw-data/example_R1.fq.gz --r2 /data/raw-data/example_R2.fq.gz\n</code></pre> </li> <li> <p>Report the results</p> <pre><code>docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.3-31f4ef89 report -d /data/results -m /data/metadata.csv --output-dir /data/report\n</code></pre> </li> <li> <p>Find your QC report in <code>/your-dir/multiqc_report.html</code></p> </li> </ol>"},{"location":"data_pipelines/transcriptomics/metadata_template/","title":"Metadata Template","text":"<p>English or Chinese?</p> <p>English means <code>With English Annotations</code>; </p> <p>Chinese means <code>With Chinese Annotations</code>;</p>"},{"location":"data_pipelines/transcriptomics/metadata_template/#latest-version","title":"Latest Version","text":"<ul> <li><code>English Version - Recommended</code> </li> <li><code>Chinese Version</code></li> </ul>"},{"location":"data_pipelines/transcriptomics/metadata_template/#previous-versions","title":"Previous Versions","text":""},{"location":"data_pipelines/transcriptomics/metadata_template/#2022051201-english","title":"2022051201 - English","text":"<pre><code>CHANGELOG: \nThis is the first commit.\n</code></pre>"},{"location":"data_pipelines/transcriptomics/metadata_template/#2022051201-chinese","title":"2022051201 - Chinese","text":"<pre><code>CHANGELOG: \nThis is the first commit.\n</code></pre>"},{"location":"data_pipelines/transcriptomics/omics_data_format/","title":"Omics Data Format","text":""},{"location":"data_pipelines/transcriptomics/omics_data_format/#rna-seq","title":"RNA-Seq","text":"<p>The data format that can be analysed online are pair-end FASTQ files, with suffixes of <code>_R1.fastq.gz</code> and <code>_R2.fastq.gz</code> or <code>_R1.fq.gz</code> and <code>_R2.fq.gz</code>.</p> <p>Your dataset must contain four groups D5, D6, F7 and M8, with at least 2 technical replicates in each group. The reason is as follows.</p> <ol> <li> <p>In order to be able to compare with our reference dataset constructed based on the four groups D5, D6, F7 and M8, your dataset must contain D5, D6, F7 and M8.</p> </li> <li> <p>The SNR is calculated based on the ratio of signal (between the four groups) to noise (technical replicates within the group), so each group contains at least two technical replicates.</p> </li> </ol> <p>Note</p> <p>In addition, there is one thing to note when using the Quartet RNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of samples. </p> <p>For example, if your data contains 8 samples(such as D5, D6, F7 and M8 * 2 technical replicates), you should fill in \"8\".</p>"},{"location":"data_pipelines/transcriptomics/omics_data_format/#mirnaseq","title":"miRNAseq","text":"<p>We haven't developed the analysis pipeline.</p>"},{"location":"data_pipelines/transcriptomics/qc_report/","title":"QC Report","text":""},{"location":"data_pipelines/transcriptomics/qc_report/#quality-metrics","title":"Quality Metrics","text":"Metric Description Range v1 Cutoff v1 Signal-to-Noise Ratio (SNR) Based on the Quartet design, a Signal-to-Noise Ratio (SNR) metric was established to gauge the performance of a platform, a lab, a protocol, or a batch in distinguishing the intrinsic biological differences (\u201csignal\u201d) among the Quartet samples from variations among technical replicates of the same sample group (\u201cnoise\u201d). Generally, a lower SNR value indicates lower discriminating power, vice versa. For an SNR value around or below zero, it means that the magnitude of signal is at a similar level as the noise or even lower than the noise. In this case, it is almost impossible to distinguish different sample groups under the high level of technical noises. Here, we used the first two principal components for calculating SNR, in correspondence with visualization in commonly used two-dimensional PCA plots. (-\u221e, +\u221e) &gt;12 Relative correlation with reference datasets (RC) Relative correlation with reference datasets was calculated based on the Pearson correlation coefficient between the ratio-based expression levels of a dataset for a given pair of groups and the corresponding ratio-based reference datasets, representing the trend of numerical consistency of the ratio-based expression profiles. Reference datasets were pre-defined datasets in the format of a geometric mean by summarizing from the fold-changes calculated from the high-quality RNAseq datasets, providing \u201cground truth\u201d for benchmarking. [-1, 1] &gt;0.89 Total score The total performance score is calculated to measure the overall quality of a dataset generated from a lab for its effectiveness in quantifying the transcriptomic differences among the four Quartet RNA reference materials by summarizing reference dataset-independent quality measurement (SNR) and reference dataset-dependent quality measurement (RC). The total score is expressed as the geometrical mean of SNR and RC. (-\u221e, +\u221e)"},{"location":"data_pipelines/transcriptomics/qc_report/#raw-data-quality-mapping-quality","title":"Raw Data Quality &amp; Mapping Quality","text":"Quality Metrics Software Description Reference Value Total.Sequences Fastqc - &gt; 10 M GC_beforemapping Fastqc - 40% - 60% total_deduplicated_percentage Fastqc - Human.percentage FastQ Screen - &gt; 90 % ERCC.percentage FastQ Screen - &lt; 5% EColi.percentage FastQ Screen - &lt; 5% Adapter.percentage FastQ Screen - &lt; 5% Vector.percentage FastQ Screen - &lt; 5% rRNA.percentage FastQ Screen - &lt; 10% Virus.percentage FastQ Screen - &lt; 5% Yeast.percentage FastQ Screen - &lt; 5% Mitoch.percentage FastQ Screen - &lt; 5% Phix.percentage FastQ Screen - &lt; 5% No.hits.percentage FastQ Screen - &lt; 5% percentage_aligned_beforemapping Qualimap - &gt; 90% error_rate Qualimap - &lt; 5% bias_53 Qualimap - GC_aftermapping Qualimap - 40% - 60% percent_duplicates Qualimap - sequence_length Qualimap - ~150 median_insert_size Qualimap - 200 - 300 mean_coverage Qualimap - ins_size_median Qualimap - 200 - 300 ins_size_peak Qualimap - 200 - 300 exonic Qualimap - 40% - 60% intronic Qualimap - 40% - 60% intergenic Qualimap - &lt; 10%"},{"location":"developers/changelog/","title":"Changelog","text":""},{"location":"developers/changelog/#news","title":"News","text":""},{"location":"developers/changelog/#april-15-2022","title":"April 15, 2022","text":"<ul> <li>Improved the performance <code>quartet-studio</code>: opening time of the first screen is from 5-6 seconds to 1-2 seconds.</li> <li>Removed unused components.</li> <li>Minimize the image size.</li> <li>Split the js library to several chunks.</li> </ul>"},{"location":"developers/changelog/#april-10-2022","title":"April 10, 2022","text":"<ul> <li>Release a new version of <code>quartet-studio</code></li> </ul>"},{"location":"getting_started/analysis_history/","title":"Analysis history","text":"<p>Comming Soon...</p>"},{"location":"getting_started/browser_and_download/","title":"Browser and download","text":"<p>Comming Soon...</p>"},{"location":"getting_started/interactive_visualization/","title":"Interactive visualization","text":"<p>Comming Soon...</p>"},{"location":"getting_started/introduction/","title":"Overview","text":"What is the Quartet Project? <p>Quality Control and Data Integration of Multi-omics Profiling</p> <p>Multi-omics (or molecular phenomics) profiling at the genomic, transcriptomic, proteomic, and metabolomic levels is the cornerstone of high-throughput technologies for discovering biomarkers for precision medicine. However, the lack of quality control procedures of multi-omics profiling during data generation and data analysis can lead to false findings, raising serious concerns about the reliability of multi-omics studies.</p> <p>The Quartet Project provides publicly accessible multi-omics reference materials and practical tools to enhance the reproducibility and reliability of multi-omics results. Well-characterized multi-omics reference materials and quality control metrics pertinent to precision medicine study purposes can be used to measure and mitigate technical variation, enabling more accurate cross-batch and cross-omics data integration in increasingly large-scale and longitudinal studies such as the International Human Phenome Project.</p>"},{"location":"getting_started/introduction/#what-is-the-quartet-data-portal","title":"What is the Quartet Data Portal?","text":""},{"location":"getting_started/qc_report/","title":"Qc report","text":"<p>Comming Soon...</p>"},{"location":"getting_started/quality_assessment_page/","title":"Quality assessment page","text":"<p>Comming Soon...</p>"},{"location":"getting_started/register_account/","title":"Register Account","text":""},{"location":"getting_started/register_account/#policy-for-account-registration","title":"Policy for account registration","text":"<p>If you want to upload your data to the platform and use the pipelines in the platform to analyze your data, you need to register an account. Otherwise, you can access the Quartet Data Portal as a guest (such as reference materials, omics data and other funtions).</p> <p>More details on the policy can be found in the document.</p>"},{"location":"getting_started/register_account/#request-reference-materials-and-register-an-account","title":"Request Reference Materials and register an account","text":"<p>You can access the Quartet Data Portal and request reference materials as a guest.</p> <p>We will receive the notification email after you submit a request for the reference materials. Our staff will contact you for further confirming your information and request (such as your organization, delivery address, required reference materials and quantity, purpose etc.). If we agree to the application, we will sent you a registration email and delivery the reference materials to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in.</p>"},{"location":"getting_started/register_account/#i-have-the-quartet-reference-materials-but-no-account","title":"I have the Quartet reference materials but no account","text":"<p>You can send an email to quartet@fudan.edu.cn for requesting an account (please let us know your name, organization, purpose etc.). After getting your request, our staff will contact you for further confirming your information and request (such as your organization, purpose etc.). If we agree to the application, we will sent you a registration email to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in.</p>"},{"location":"getting_started/request_omics_data/","title":"Access Quartet MultiOmics Data","text":""},{"location":"getting_started/request_omics_data/#1-data-policies","title":"1. Data Policies","text":"<p>The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through the Quartet Data Portal in order for us to improve the reference datasets and to better serve the community.</p> <p>More details on the data policies can be found in the document.</p>"},{"location":"getting_started/request_omics_data/#2-how-to-bulk-download-the-omics-data-files-with-browser","title":"2. How to bulk download the omics data files with browser?","text":"<ul> <li> <p>Filter and select your expected files</p> </li> <li> <p>Add them into file cart</p> </li> <li> <p>Go to file cart by clicking <code>Cart Files</code> button</p> </li> <li> <p>Click <code>Download Files</code> to downloading all files in cart.</p> </li> </ul>"},{"location":"getting_started/request_omics_data/#3-how-to-bulk-download-the-omics-data-files-with-file-transfer-tool","title":"3. How to bulk download the omics data files with file transfer tool?","text":"<ul> <li> <p>Download a metadata table from multi-omics data page.(such as genomics data in Multiomics Data -&gt; Genomics Data</p> </li> <li> <p>Get the md5sum of files which you want to download from the metadata table.</p> </li> <li> <p>Follow the following docs to download your expected files.</p> </li> </ul>"},{"location":"getting_started/request_omics_data/#31-download-file-transfer-tool-biominer-aget","title":"3.1 Download <code>file transfer tool - biominer-aget</code>","text":"<p>Click the link to download <code>BioMiner Aget</code>: </p> <ul> <li> <p>Linux (CentOS, Debian/Ubuntu or Others)</p> </li> <li> <p>Mac (Intel, not m1 &amp; m2 version)</p> </li> <li> <p>Windows</p> </li> </ul> <p>Copy the biominer-aget_xxx binary into /usr/bin/biominer-aget_xxx or any other directory which in PATH variable.</p> <p>Note</p> <ol> <li> <p>The <code>chunk_size</code> and <code>concurrency</code> parameters are related with the download speed. There may be tens or hundreds of times the difference, so it's worth taking some time to find the best one.</p> </li> <li> <p>The biominer-aget binary is not available for mac (arm, m1 &amp; m2).</p> </li> <li> <p>Not each file can be found in all these repos, so you need to specify a repo name when you downloading expected file.</p> </li> </ol>"},{"location":"getting_started/request_omics_data/#32-download-a-data-file-with-biominer-aget","title":"3.2 Download a data file with biominer-aget","text":"<p>e.g. you want to download the file with UUID <code>0023a688-6569-44d7-a2cf-b031f4af8cdd</code> or Hash (such as md5sum, sha128...) <code>d4e50c8edbf5215fbe2afa1540f7c968</code> from the repository biominer.fudan-pgx, you can run the following command:</p>"},{"location":"getting_started/request_omics_data/#for-mac-intel-users","title":"For Mac (Intel) Users","text":"<pre><code>biominer-aget_x86-64_macosx --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000\n## or\nbiominer-aget_x86-64_macosx --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000\n## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it.\nbiominer-aget_x86-64_macosx --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node\n</code></pre>"},{"location":"getting_started/request_omics_data/#for-linux-users","title":"For Linux Users","text":"<pre><code>biominer-aget_x86-64_linux --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000\n## or\nbiominer-aget_x86-64_linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000\n## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it.\nbiominer-aget_x86-64_linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node\n</code></pre>"},{"location":"getting_started/request_omics_data/#for-windows-users","title":"For Windows Users","text":"<p>If you download the biominer-aget_xxx binary into C://Users/xxx/Desktop, you can use the following command to download data file from QDP.</p> <pre><code>cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget_x86-64_windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo gsa\n\n## or\n\ncmd /c C:\\Users\\xxx\\Desktop\\biominer-aget_x86-64_windows --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --repo gsa --chunk_size 1m --concurrency 1000\n\n## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it.\n\ncmd /c C:\\Users\\xxx\\Desktop\\biominer-aget_x86-64_windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo node\n</code></pre> <pre><code>$ biominer-aget --help\nBiominer Aget 0.3.7\nJingcheng Yang &lt;yjcyxky@163.com&gt;\nAn Index Engine for Omics Data Files\n\nUSAGE:\n    biominer-aget [FLAGS] [OPTIONS]\nFLAGS:\n    -D, --debug      Activate debug mode\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -a, --api-server &lt;api-server&gt;      The api server address\n    -k, --chunk_size &lt;chunk_size&gt;      The number ofinterval length of each concurrent request [default: '50m']\n-c, --concurrency &lt;concurrency&gt;    The number of concurrency request [default: 10]\n--dns-timeout &lt;dns-timeout&gt;    DNS Timeout(seconds) of request [default: 10]\n-g, --guid &lt;guid&gt;                  The guid of the file you want to download, e.g. biominer.fudan-pgx/00006134-c655-\n                                       4bbe-9144-0ee86da83902\n    -H, --hash &lt;hash&gt;                  The hash of the file you want to download, e.g. b47ee06cdf62847f6d4c11bb12ac1ae0\n    -o, --output-dir &lt;output-dir&gt;      Output directory [default: ./]\n-p, --password &lt;password&gt;          Password for the biominer api server [default: anonymous]\n-r, --repo &lt;repo&gt;                  Which data repository you want to download from [default: node]  [possible\n                                       values: node, gsa, s3, oss, minio]\n--retries &lt;retries&gt;            The maximum times of retring [default: 0]\n--retry-wait &lt;retry-wait&gt;      The seconds between retries [default: 0]\n-t, --timeout &lt;timeout&gt;            Timeout(seconds) of request [default: 60]\n-u, --username &lt;username&gt;          Username for the biominer-indexd api server [default: anonymous]\n</code></pre>"},{"location":"getting_started/request_omics_data/#4-how-do-you-know-a-file-is-stored-at-which-repo","title":"4. How do you know a file is stored at which repo?","text":"<p>Please access the BioMiner Indexd service and query file by md5sum, filename, or other metadata.</p> <p>When you find the record of a file, you can see more information as the following picture.</p> <p>In the picture, you can see the URLs field, it can tell you the file is stored at which repos.</p> <p></p>"},{"location":"getting_started/request_omics_data/#5-why-biominer-indexd","title":"5. Why BioMiner Indexd?","text":"<p>We will release our data to multiple repos (such as NODE, GSA, SRA, ENA etc.), for your convenience, we provide the BioMiner Indexd service for aggregating all these repos.</p> <p>BioMiner Indexd is a hash-based data indexing and tracking service providing globally unique identifiers.</p>"},{"location":"getting_started/request_omics_data/#6-what-multi-omics-data-do-we-provide","title":"6. What multi-omics data do we provide?","text":""},{"location":"getting_started/request_omics_data/#genomics","title":"Genomics","text":"<p>Quartet DNA reference materials have been extensively sequenced by short-read and long-read technologies. Short-read WGS datasets were generated with depth ranging from 30-60, by employing PCR-free and PCR libraries on multiple short-read sequencing platforms, including Illumina Hiseq XTen, Illumina Novaseq, MGISEQ-2000 and DNBSEQ-T7. We have sequenced 180 WGS libraries, 248 WES libraries in total. Long-read sequencing datasets have been generated using 10X genomics, Oxford Nanopore Technologies, BioNano Genomics, and Pacific Biosciences Sequel and Sequel II with CLR and CCS HiFi modes.</p>"},{"location":"getting_started/request_omics_data/#transcriptomics","title":"Transcriptomics","text":"<p>RNA-seq datasets from reference materials were then obtained, consisting of 252 RNA-seq libraries from 21 batches which were generated by eight laboratories using two library construction protocols (poly(A) selection and rRNA depletion) and two sequencing platforms (Illumina NovaSeq and BGI DNBseq). Here, a batch of RNA-seq experiments was defined as libraries from a standard sample set, consisting of 12 tubes with each representing one of the triplicates of the four RNA reference sample groups, which were conducted library construction and sequencing experiments concurrently.</p>"},{"location":"getting_started/request_omics_data/#proteomics","title":"Proteomics","text":"<p>Currently we sent 6 units of Quartet Protein Reference Materials to 6 labs, in which 6 batches of raw datasets and profiled datasets were generated in their in-house LC-MS/MS systems by label-free quantitation (both DDA and DIA). Our Cooperators also extracted human proteins (labeled as \u201cLot1\u201d in our metadata) from the immortalized B-lymphoblastoid cell lines and have generated 26 batches of DDA-based profiled datasets since 2017.</p>"},{"location":"getting_started/request_omics_data/#metabolomics","title":"Metabolomics","text":"<p>We dispensed three biological replicates of each unit of the Quartet Metabolite Reference Materials to six laboratory platforms of five companies. These six laboratories produced a total of 204 metabolic quantitative profiles in 17 datasets (batches) using targeted or un-targeted metabolomics strategies. Furthermore, based on the large amount of copies of Quartet metabolite reference materials, we regularly generated targeted metabolomics data with three technical replicates for each unit of the Quartet Metabolite Reference Materials for up to one year in Metabo-Profile (L4).</p>"},{"location":"getting_started/request_reference_materials/","title":"Request Reference Materials","text":"<p>If you want to request reference materials, you can access the Quartet Data Portal and request reference materials as a guest. As the following figure shows, you can click the <code>Request xx Materials</code> button to request related reference materials. After you enter the request page, you can follow the instructions to fill in the form and submit your request. We will review your request and contact you as soon as possible.</p> <p></p> <p>More details on the reference materails policy can be found in the document.</p>"},{"location":"getting_started/select_pipeline/","title":"Select pipeline","text":"<p>Comming Soon...</p>"},{"location":"getting_started/step_by_step_guide_dna/","title":"Quality Assessment for WGS","text":""},{"location":"getting_started/step_by_step_guide_metabolite/","title":"Quality Assessment for Metabolomics","text":""},{"location":"getting_started/step_by_step_guide_protein/","title":"Quality Assessment for Proteomics","text":""},{"location":"getting_started/step_by_step_guide_rna/","title":"Quality Assessment for Transcriptomics","text":""},{"location":"getting_started/submit_data/","title":"Submit Your Raw Omics Data","text":""},{"location":"getting_started/submit_data/#data-submission-policy","title":"Data submission policy","text":"<p>The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through Public data warehouse (Recommended, such as SRA, ENA, GSA etc.) or the Quartet Data Portal (for analyzing your data online) in order for us to improve the reference datasets and to better serve the community.</p> <p>More details on the policy can be found in the document.</p>"},{"location":"getting_started/submit_data/#how-to-upload-and-analyze-your-data","title":"How to upload and analyze your data?","text":"<p>For convenience, we provide a web-based data analysis platform for users to analyze their data. Users can upload their in-house omics data generated with the Quartet reference sample, select the specific pipeline and parameters, and obtain the analysis results and QC results, which can be managed by the Quartet Data Portal.</p> <p>So if you only want to analyze your data with Quartet pipelines online, you can upload your data to the Quartet Data Portal. Please follow the steps:</p> <p>1) Create a dataset by clicking the 'Register &amp; Upload Your Data'</p> <p>2) Get your access key and secret by clicking 'New Token' button</p> <p>3) Review the data specification before uploading files</p> <p>4) Upload your omics data files and metadata files</p> <p>5) Verify and confirm Uploaded files by clicking 'Check' button</p> <p>After you checking your data, you can choose the pipeline and parameters to analyze your data.</p>"},{"location":"getting_started/submit_data/#tools-for-uploading-data","title":"Tools for uploading data","text":"<p>OSS Utility or OSS Browser</p>"},{"location":"getting_started/toolbars/","title":"Toolbars","text":"<p>Comming Soon...</p>"},{"location":"policies/account_registration_policy/","title":"Account Registration Policy","text":"<p>If you want to use the pipelines in the platform to analyze your data or submit your data to the platform, you need to register an account. The account registration policy is as follows:</p> <ol> <li> <p>The account registration is free.</p> </li> <li> <p>The account registration is open to all users who are interested in the platform and agree to abide by the rules of the platform.</p> </li> <li> <p>You need to contact the administrator to register an account. Please provide your name, affiliation, purpose and email address (as the username) in the email. After the administrator approves your application, you will receive an email with registration link. You can use the link to set your password and login to the platform. we will reply to you within 3-7 working days.</p> </li> <li> <p>The administrator reserves the right to reject the following applications:</p> <ul> <li> <p>The application is not from a valid email address (personal email address is not allowed).</p> </li> <li> <p>The application is not from a valid affiliation.</p> </li> <li> <p>The application is a commercial purpose (e.g. use the platform to provide services to others and charge fees).</p> </li> </ul> </li> <li> <p>The administrator reserves the right to suspend or terminate the account if the user violates the following rules:</p> <ul> <li> <p>The user uses the platform for commercial purposes.</p> </li> <li> <p>The user uses the platform to provide services to others.</p> </li> <li> <p>The user uses the platform to analyze data which is not generated with the quartet reference materials.</p> </li> <li> <p>The user uses the platform to conduct illegal activities.</p> </li> <li> <p>The user uses the platform to conduct activities that endanger the security of the platform.</p> </li> <li> <p>The user uses the platform to conduct activities that endanger the security of other users.</p> </li> </ul> </li> </ol>"},{"location":"policies/data_request_policy/","title":"Data Request Policy","text":"<p>If you want to get all of data which are published on the platform, you don't need to register an account. Only need to access the download page, choose the data you want and download the metadata table which contains the md5sum of each data file. Then you can use the md5sum to download the data from the related data repositories. You can follow the tutorial to download the data. Or you can download the related data by clicking the download button on the data page.</p> <ul> <li>All data are free for all users for academic use. If you want to use the data for commercial purposes, please contact the administrator.</li> </ul>"},{"location":"policies/data_submission_policy/","title":"Data Submission Policy","text":"<p>If you want to submit your data to the platform, you need to register an account. Then you can access the submit page to submit your data and metadata table. You can follow the tutorial to submit your data.</p> <p>The following is the data submission policy:</p>"},{"location":"policies/data_submission_policy/#purpose","title":"Purpose","text":"<p>The purpose of this policy is to establish guidelines for submitting data to ensure its integrity, accuracy, and consistency, while maintaining privacy and security.</p>"},{"location":"policies/data_submission_policy/#scope","title":"Scope","text":"<p>This policy applies to all data submitted by internal and external parties.</p>"},{"location":"policies/data_submission_policy/#submission-guidelines","title":"Submission Guidelines","text":"<ul> <li> <p>All data should be submitted in the requested format and within the specified metadata template.</p> <ul> <li> <p>Genomics Data Submission Guidelines</p> </li> <li> <p>Transcriptomics Data Submission Guidelines</p> </li> <li> <p>Proteomics Data Submission Guidelines</p> </li> <li> <p>Metabolomics Data Submission Guidelines</p> </li> </ul> </li> <li> <p>Data must be accurate, complete, and relevant.</p> </li> <li> <p>Data sources must be appropriately referenced. If you are submitting your data to a public repository, please provide the accession number in your metadata table. <code>We strongly recommend that you submit your data to a public repository (e.g SRA, ENA, GSA etc.) and submit the metadata table to the platform. After getting the metadata table, we will check the data and metadata table. If there is no problem, we will publish the data on the platform and announce the uploader of the data on the data page.</code></p> </li> <li> <p>Personal and sensitive data must be anonymized or de-identified unless otherwise specified and agreed upon.</p> </li> <li> <p>If you are submitting data on behalf of an organization, you must have the authority to do so.</p> </li> </ul>"},{"location":"policies/data_submission_policy/#responsibility-for-data-quality","title":"Responsibility for Data Quality","text":"<ul> <li> <p>The individual or entity submitting the data is responsible for its quality, and must take appropriate steps to verify accuracy and completeness.</p> </li> <li> <p>The Quartet team reserves the right to review all data submissions for quality and compliance, and to reject submissions that fail to meet the established criteria or violate this policy.</p> </li> <li> <p>This policy may be revised periodically based on changes in legal, ethical, or technological contexts. All changes will be communicated to the relevant parties.</p> </li> <li> <p>Failure to comply with this policy may result in rejection of data, termination of data access, and potential legal action.</p> </li> </ul> <p>Note: This policy must be understood and agreed upon before submitting data. For any questions, contact the Quartet Team</p>"},{"location":"policies/reference_materials_policy/","title":"Reference Materials Policy","text":"<p>CAUTION</p> <p>If you want to request reference materials, you don't need to register an account. Only need to access the request page, choose the materials you want and fill in the form. We will reply to you within 3-7 working days. If not received the confirmation email, please check the spam folder in your email box. If you have any questions, please contact the administrator.</p> <p>Reference materials policy is as follows:</p> <ol> <li> <p>The reference materials are free for academic use. If you want to use the reference materials for commercial purposes, please contact the administrator.</p> </li> <li> <p>The Quartet team reserves the right to reject the following applications:</p> <ul> <li> <p>Incomplete Applications: Applications that are incomplete or contain inaccurate information may be rejected. This includes failure to provide necessary documentation or provide required details.\u21b3</p> </li> <li> <p>Non-Compliant Applications: Applications that do not adhere to Quartet's rules, regulations, or policies, as outlined in application instructions or Quartet's terms and conditions, may be rejected.</p> <ul> <li> <p>Request unreasonable amount of reference materials.</p> </li> <li> <p>Request reference materials for commercial purposes, but not contact the administrator to discuss the details, get approval and sign the agreement.</p> </li> <li> <p>Don't agree to charge the necessary fees (such as shipping fees).</p> </li> <li> <p>Don't agree to provide the feedback about how to use the reference materials and the results of the analysis (It can be a publication, a poster, a presentation, or a report).</p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"roadmap/genomics/","title":"Genomics","text":""},{"location":"roadmap/genomics/#mission","title":"Mission","text":""},{"location":"roadmap/genomics/#roadmap","title":"Roadmap","text":"Task Category Description Status Plan Docs QDP Link Version First Version QC APP for WGS Quality control of germline variants calling results using a Chinese Quartet family (FastQ/VCF -&gt; QC Results) Finished - README Access v0.2.0"},{"location":"tools/choppy_apps/","title":"Choppy apps","text":"<p>Comming Soon...</p>"},{"location":"tools/data_repo/","title":"Data repo","text":"<p>Comming Soon...</p>"},{"location":"tools/multireport/","title":"Multireport","text":"<p>Comming Soon...</p>"},{"location":"tools/ossbrowser/","title":"OSSBrowser","text":"<p><code>ossbrowser</code> is a graphical management tool to upload data to the Quartet Data Portal.</p> Name Recommendation Notice Category Characteristics Expected Average Speed OSS Browser Low Only use it when the total data volume is less than 100GB and the size of one single file is less than 5GB GUI Tool Easy, but slower than OSSUtil 1-30MB/s"},{"location":"tools/ossbrowser/#1-download-and-installation","title":"1. Download and installation","text":"<p>The ossbrowser supports the following operating systems: Windows, Linux, and macOS. You can download and install the ossbrowser version that best suits your requirements. </p> <ul> <li>Click here to download ossbrowser and see more details.</li> </ul>"},{"location":"tools/ossbrowser/#2-log-on-to-ossbrowser","title":"2. Log on to ossbrowser","text":"<p>You will get the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), Preset Oss Path (uploadPath), and Auth-Token (authorizedCode) from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website.</p> <p>The contents of the data.json file are as follows:</p> <pre><code>{\n  \"uploadPath\": \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\",\n  \"region\": \"oss-cn-shanghai\",\n  \"durationHours\": 12,\n  \"expiration\": \"Thu Sep 23 2021 22:02:21 GMT+0800\",\n  \"accessKey\": \"STS.NSw4TPayxZcbeXQbDfoZiHE16\",\n  \"accessSecret\": \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\",\n  \"stsToken\": \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\",\n  \"authorizedCode\": \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\"\n}\n</code></pre> <p>There are two methods to log on to ossbrowser, AK Login and Token Login.</p> <p>a. AK Login</p> <p>You need to fill in the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), and Preset Oss Path (uploadPath) as follows:</p> <p></p> <p>b. Token Login</p> <p>You need to fill in the Auth-Token (authorizedCode) as follows:</p> <p></p> <p>Then, you will see the following screen\uff1a</p> <p></p>"},{"location":"tools/ossbrowser/#3-click-upload-to-upload-files","title":"3. Click \"Upload\" to upload files","text":"<ul> <li> <p>You can click \"Upload\" button to upload your omics data files and metadata files, and then verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website.</p> </li> <li> <p>You only have 12 duration hours, please upload as soon as possible.</p> </li> </ul>"},{"location":"tools/ossutil/","title":"OSSUtil","text":"<p><code>ossutil</code> is a user friendly command line tool to upload data to the Quartet Data Portal. It supports the following operating systems: Windows, Linux, and macOS. You can download and install the ossutil version that best suits your requirements. </p> Name Recommendation Notice Category Characteristics Expected Average Speed OSSUtil High Recommend to use it on a Linux server with wired network Terminal Tool Fast, Powerful and Supporting resuming from a breakpoint 40-100MB/s <ul> <li>Click here to download ossutil.</li> <li>Click here to see more details in ossutil.</li> </ul> <p>Here is an example that install ossutil on Linux.</p>"},{"location":"tools/ossutil/#1-download-the-ossutil-installation-package","title":"1. Download the ossutil installation package","text":"<pre><code>wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64\n</code></pre>"},{"location":"tools/ossutil/#2-modify-the-execution-permissions-of-the-file","title":"2. Modify the execution permissions of the file","text":"<pre><code>chmod 755 ossutil64\n</code></pre>"},{"location":"tools/ossutil/#3-generate-a-configuration-file-in-interactive-mode","title":"3. Generate a configuration file in interactive mode","text":"<p>a. Run the following command:</p> <pre><code>./ossutil64 config\n</code></pre> <p>b. Configure the path of the configuration file as prompted.</p> <p>Note</p> <p>We recommend that you use the default path for the configuration file by pressing the Enter key. Enter the name of the configuration file. The file name can contain a path. The default path is /home/user/.ossutilconfig. If you press the Enter key without specifying a different name, the file is generated in the default path. If you want to generate the file in another path, set the --config-file configuration item to the path that you want to use. </p> <p>c. Set the language of ossutil as prompted.</p> <p>Note</p> <p>Enter the language: CH or EN. The default language is CH. The configuration of this parameter takes effect after the config command is run. </p> <p>d. Configure the parameters, including Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token as prompted.</p> <ul> <li>The endpoint is http://oss-cn-shanghai.aliyuncs.com.</li> <li> <p>The AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken)  are from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website.</p> <p>The contents of the data.json file are as follows:</p> <pre><code>{\n\"uploadPath\": \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\",\n\"region\": \"oss-cn-shanghai\",\n\"durationHours\": 12,\n\"expiration\": \"Thu Sep 23 2021 22:02:21 GMT+0800\",\n\"accessKey\": \"STS.NSw4TPayxZcbeXQbDfoZiHE16\",\n\"accessSecret\": \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\",\n\"stsToken\": \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\",\n\"authorizedCode\": \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\"\n}\n</code></pre> <p>The parameters are as prompted:</p> <ul> <li> <p>Please enter endpoint: <code>http://{region}.aliyuncs.com, such as http://oss-cn-shanghai.aliyuncs.com</code></p> </li> <li> <p>Please enter accessKeyID: <code>{accessKey}, such as STS.NSw4TPayxZcbeXQbDfoZiHE16</code></p> </li> <li> <p>Please enter accessKeySecret: <code>{accessSecret}, such as 38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz</code></p> </li> <li> <p>Please enter stsToken: <code>{stsToken}, such as CAIS2wR1q6Ft5B2yfSjIr5DCf....</code></p> </li> </ul> </li> </ul>"},{"location":"tools/ossutil/#4-upload-files","title":"4. Upload files","text":"<p>Run the cp command to upload local files or directories to Object Storage Service (OSS).</p> <ul> <li> <p>Click here to see more details in cp.</p> </li> <li> <p>You can verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website.</p> </li> <li> <p>You only have 12 duration hours, please upload as soon as possible (But don't worry, when you started the uploading, the process will not be interrupted until finished or killed by you).</p> </li> </ul> <pre><code>./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/\n</code></pre>"},{"location":"tools/ossutil_cn/","title":"OSSUtil\u5feb\u901f\u6307\u5357","text":"<p><code>ossutil</code> \u4e00\u6b3e\u7528\u6237\u53cb\u597d\u7684\u7ec8\u7aef\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u4e0a\u4f20\u6570\u636e\u81f3Quartet Data Portal\u7cfb\u7edf\u3002ossutil\u652f\u6301\u5728Windows\u3001Linux\u3001macOS\u7b49\u7cfb\u7edf\u4e2d\u8fd0\u884c\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u73af\u5883\u4e0b\u8f7d\u548c\u5b89\u88c5\u5408\u9002\u7684\u7248\u672c\u3002 </p> \u5de5\u5177\u540d\u79f0 \u63a8\u8350\u7ea7\u522b \u6ce8\u610f\u4e8b\u9879 \u5de5\u5177\u7c7b\u578b \u7279\u70b9 \u9884\u671f\u5e73\u5747\u901f\u5ea6 OSSUtil \u5f3a\u70c8\u63a8\u8350 \u5efa\u8bae\u5728Linux\u670d\u52a1\u5668\u548c\u6709\u7ebf\u7f51\u7edc\u4e0b\u4f7f\u7528 \u7ec8\u7aef\u5de5\u5177 \u652f\u6301\u5927\u91cf\u6587\u4ef6\u5e76\u53d1\u4e0a\u4f20\u3001\u65ad\u70b9\u7eed\u4f20\u53ca\u6587\u4ef6\u76ee\u5f55\uff08\u6587\u4ef6\u5939\uff09\u7684\u4e0a\u4f20 40-100MB/s <ul> <li>\u70b9\u51fb \u94fe\u63a5\u4e0b\u8f7dossutil</li> <li>\u70b9\u51fb \u94fe\u63a5\u67e5\u770b\u66f4\u591a\u5e2e\u52a9\u4fe1\u606f</li> </ul> <p>\u5982\u4e0b\u4ee5Linux\u7248ossutil\u5b89\u88c5\u4e3a\u4f8b\uff0c\u8bf4\u660eossutil\u5b89\u88c5\u4e0e\u4f7f\u7528</p>"},{"location":"tools/ossutil_cn/#1-ossutil","title":"1. \u4e0b\u8f7dossutil","text":"<pre><code>wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64\n</code></pre>"},{"location":"tools/ossutil_cn/#2","title":"2. \u4fee\u6539\u6587\u4ef6\u53ef\u6267\u884c\u6743\u9650","text":"<pre><code>chmod 755 ossutil64\n</code></pre>"},{"location":"tools/ossutil_cn/#3ossutil","title":"3.\u901a\u8fc7\u4ea4\u4e92\u6a21\u5f0f\u751f\u6210ossutil\u914d\u7f6e\u6587\u4ef6","text":"<p>a. \u8fd0\u884c\u5982\u4e0b\u547d\u4ee4\uff1a</p> <pre><code>./ossutil64 config\n</code></pre> <p>b. \u4f9d\u636e\u63d0\u793a\u4fe1\u606f\u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u8def\u5f84\u5373\u53ef\uff09</p> <p>c. \u4f9d\u636e\u63d0\u793a\u9009\u62e9\u8bed\u8a00\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u9009\u9879\u5373\u53ef\uff09</p> <p>d. \u4f9d\u636e\u63d0\u793a\u914d\u7f6e\u4ee5\u4e0b\u53c2\u6570, \u5305\u62ec Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token.</p> <ul> <li>Endpoint\u586b\u5199 http://oss-cn-shanghai.aliyuncs.com</li> <li>AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken) \u53ef\u4eceQDP\u7cfb\u7edf\u4e0b\u8f7d\u7684 data.json \u6587\u4ef6\u4e2d\u83b7\u53d6\uff0c\u5176\u901a\u8fc7\u70b9\u51fb\"New Token\"\u751f\u6210</li> </ul> <p></p> <p>data.json\u6587\u4ef6\u793a\u4f8b\u5982\u4e0b\u6240\u793a:</p> <pre><code>{\n\"uploadPath\": \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\",\n\"region\": \"oss-cn-shanghai\",\n\"durationHours\": 12,\n\"expiration\": \"Thu Sep 23 2021 22:02:21 GMT+0800\",\n\"accessKey\": \"STS.NSw4TPayxZcbeXQbDfoZiHE16\",\n\"accessSecret\": \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\",\n\"stsToken\": \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\",\n\"authorizedCode\": \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\"\n}\n</code></pre> <p>\u53c2\u6570\u793a\u4f8b\u5982\u4e0b:</p> <ul> <li> <p>\u8bf7\u8f93\u5165endpoint: <code>http://oss-cn-shanghai.aliyuncs.com</code></p> </li> <li> <p>\u8bf7\u8f93\u5165accessKeyID: <code>{accessKey}, \u4f8b\u5982\uff1aSTS.NSw4TPayxZcbeXQbDfoZiHE16</code></p> </li> <li> <p>\u8bf7\u8f93\u5165accessKeySecret: <code>{accessSecret}, \u4f8b\u5982\uff1a38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz</code></p> </li> <li> <p>\u8bf7\u8f93\u5165stsToken: <code>{stsToken}, \u4f8b\u5982\uff1aCAIS2wR1q6Ft5B2yfSjIr5DCf....</code></p> </li> </ul>"},{"location":"tools/ossutil_cn/#4","title":"4. \u4e0a\u4f20\u6587\u4ef6","text":"<p>\u8fd0\u884cossutil\u7684cp\u547d\u4ee4\u5373\u53ef\u5c06\u672c\u5730\u7684\u6587\u4ef6\u6216\u8005\u76ee\u5f55\u4e0a\u4f20\u81f3QDP\u7cfb\u7edf\u5b58\u50a8\u7cfb\u7edf</p> <ul> <li> <p>\u70b9\u51fb\u94fe\u63a5\u67e5\u770b<code>cp\u547d\u4ee4</code>\u66f4\u591a\u5e2e\u52a9\u4fe1\u606f</p> </li> <li> <p>\u5728\u786e\u8ba4\u4e0a\u4f20\u5b8c\u6240\u6709\u6587\u4ef6\u540e\uff0c\u8bf7\u56de\u5230QDP\u7f51\u7ad9\uff0c\u70b9\u51fb<code>Check\u6309\u94ae</code>\u786e\u8ba4\u60a8\u7684\u6570\u636e</p> </li> <li> <p>Token\u6709\u6548\u671f\u4e3a12\u5c0f\u65f6\u3002\u4f46\u8bf7\u52ff\u62c5\u5fc3\uff0c\u4e00\u65e6\u6587\u4ef6\u5f00\u59cb\u4e0a\u4f20\u5219\u6574\u4e2a\u8fc7\u7a0b\u4e0d\u4f1a\u53d7Token\u8fc7\u671f\u7684\u5f71\u54cd\uff0c\u9664\u975e\u60a8\u4e3b\u52a8\u7ed3\u675f\u6389\u6216\u8005ossutil\u610f\u5916\u9000\u51fa\u3002\u6b64\u5916\uff0c\u82e5Token\u8fc7\u671f\uff0c\u60a8\u53ef\u4ee5\u56de\u5230QDP\u7f51\u7ad9\u518d\u6b21\u9488\u5bf9\u76f8\u540c\u8def\u5f84\u751f\u6210Token\uff0c\u518d\u6b21\u4e0a\u4f20\u76f8\u5e94\u6587\u4ef6\u3002\u56e0ossutil\u652f\u6301\u65ad\u70b9\u7eed\u4f20\uff0c\u56e0\u6b64\u5c06\u51cf\u8f7bToken\u8fc7\u671f\u5bf9\u60a8\u6570\u636e\u4e0a\u4f20\u6548\u7387\u7684\u5f71\u54cd</p> </li> <li> <p>\u82e5\u60a8\u671f\u671b\u4e0a\u4f20\u6574\u4e2a\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\uff0c\u8bf7\u6307\u5b9a<code>-r</code>\u53c2\u6570</p> </li> <li> <p>\u5efa\u8bae\u60a8\u5c3d\u53ef\u80fd\u5c06\u4e00\u6b21\u5206\u6790\u6240\u9700\u7684\u6587\u4ef6\u653e\u5230\u4e0d\u540c\u7684\u5b50\u76ee\u5f55\u4e0b\uff0c\u8fd9\u5c06\u6709\u52a9\u4e8e\u60a8\u540e\u7eed\u6311\u9009\u9884\u671f\u6587\u4ef6\u5b8c\u6210\u5206\u6790</p> </li> <li> <p>\u82e5\u60a8\u4e0a\u4f20\u6587\u4ef6\u7684\u901f\u5ea6\u5c0f\u4e8e\u9884\u671f\uff0c\u8bf7\u786e\u8ba4\u60a8\u4f7f\u7528\u7684\u662f\u6709\u7ebf\u7f51\u7edc\uff0c\u4e14\u4e3a\u5343\u5146\u7f51\u5361\u3002\u6b64\u5916\uff0c\u60a8\u53ef\u4ee5\u8c03\u6574<code>--parallel</code>\u4e0e<code>--part-size</code>\u53c2\u6570\u6765\u4f18\u5316</p> </li> </ul> <pre><code>./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/\n</code></pre>"},{"location":"tools/visualization_tools/","title":"Visualization tools","text":"<p>Comming Soon...</p>"}]}